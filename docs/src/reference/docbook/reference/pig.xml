<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0"  xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="pig">

	<title>Pig support</title>
	
	<para>For <ulink url="http://pig.apache.org">Pig</ulink> users, SHDP provides easy creation and configuration of <interfacename>PigServer</interfacename> instances for registering and executing scripts either locally
	or remotely. In its simplest form, the declaration looks as follows:</para>
	
	<programlisting language="xml"><![CDATA[<hdp:pig />]]></programlisting>
	
	<para>This will create a <interfacename>org.springframework.data.hadoop.pig.PigServerFactory</interfacename> instance, named <literal>pigFactory</literal>, a factory that creates <literal>PigServer</literal> instances on demand 
	configured with a default <interfacename>PigContext</interfacename>,  executing scripts in <literal>MapReduce</literal> mode. The factory is needed since <literal>PigServer</literal> is not thread-safe and thus cannot
	be used by multiple objects at the same time.
	
	In typical scenarios however, one might want to connect to a remote Hadoop tracker and register some scripts automatically so let us take a look of how the configuration might look like:</para>
	
	<programlisting language="xml"><![CDATA[<pig-factory exec-type="LOCAL" job-name="pig-script" configuration-ref="hadoopConfiguration" properties-location="pig-dev.properties" 
   xmlns="http://www.springframework.org/schema/hadoop">
     source=${pig.script.src}
   <script location="org/company/pig/script.pig">
     <arguments>electric=sea</arguments>
   </script>
   <script>
     A = LOAD 'src/test/resources/logs/apache_access.log' USING PigStorage() AS (name:chararray, age:int);
     B = FOREACH A GENERATE name;
     DUMP B;
   </script>
</pig-factory> />]]></programlisting>
	
	<para>The example exposes quite a few options so let us review them one by one. First the top-level pig definition configures the pig instance: the execution type, the Hadoop configuration used and the job name. Notice that
	additional properties can be specified (either by declaring them inlined or/and loading them from an external file) - in fact, <literal><![CDATA[<hdp:pig-factory/>]]></literal> just like the rest of the libraries configuration
	elements, supports common properties attributes as described in the <link linkend="hadoop:config:properties">hadoop configuration</link> section.</para>
	<para>The definition contains also two scripts: <literal>script.pig</literal> (read from the classpath) to which one pair of arguments, 
	relevant to the script, is passed (notice the use of property placeholder) but also an inlined script, declared as part of the definition, without any arguments.</para>
	
	<para>As you can tell, the <literal>pig-factory</literal> namespace offers several options pertaining to Pig configuration.</para>
	
	<section id="pig:runner">
	    <title>Running a Pig script</title>
	
		<para>Like the rest of the Spring Hadoop components, a runner is provided out of the box for executing Pig scripts, either inlined or from various locations through <literal>pig-runner</literal> element:</para>    
	    
	    <programlisting language="xml"><![CDATA[<hdp:pig-runner id="pigRunner" run-at-startup="true">
   <hdp:script>
		A = LOAD 'src/test/resources/logs/apache_access.log' USING PigStorage() AS (name:chararray, age:int);
		...
   </hdp:script>
   <hdp:script location="pig-scripts/script.pig"/>
</hdp:pig-runner>]]></programlisting>
	   	
		<para>The runner will trigger the execution during the application start-up (notice 
		the <literal>run-at-startup</literal> flag which is by default <literal>false</literal>). Do note that the runner will not run unless triggered manually or if <literal>run-at-startup</literal> is set to <literal>true</literal>.
		Additionally the runner (as in fact do all <link linkend="runners">runners</link> in SHDP) allows one or
		multiple <literal>pre</literal> and <literal>post</literal> actions to be specified to be executed before and after each run. Typically other runners (such as other jobs or scripts) can be specified but any JDK <literal>Callable</literal> can be 
		passed in. For more information on runners, see the <link linkend="runners">dedicated</link> chapter.</para>
	
		<section id="pig:tasklet">
			<title>Using the Pig tasklet</title>
	
			<para>For Spring Batch environments, SHDP provides a dedicated tasklet to execute Pig queries, on demand, as part of a batch or workflow. The declaration is pretty straightforward:</para>
			
			<programlisting language="xml"><![CDATA[<hdp:pig-tasklet id="pig-script">
   <hdp:script location="org/company/pig/handsome.pig" />
</hdp:pig-tasklet>]]></programlisting>

			<para>The syntax of the scripts declaration is similar to that of the <literal>pig</literal> namespace.</para>	
		</section>
	</section>
	
	<section id="pig:template">
		<title>Interacting with the Pig API</title>
		
		<para>For those that need to programmatically interact directly with Pig , Spring for Apache Hadoop provides a dedicated <ulink url="http://en.wikipedia.org/wiki/Template_method_pattern">template</ulink>, 
		similar to the aforementioned <literal>HiveTemplate</literal>. The template handles the redundant, boiler-plate code, required for interacting with Pig such as creating a new <literal>PigServer</literal>, 
		executing the scripts, catching any exceptions and performing clean-up. One can programmatically execute scripts but also interact with the Hive API through the <literal>PigServerCallback</literal>.
		For example:</para>
		
		<programlisting language="xml"><![CDATA[<hdp:pig-factory ... />
<!-- Pig template wires automatically to 'pigFactory'-->
<hdp:pig-template />
	
<!-- use component scanning-->
<context:component-scan base-package="some.pkg" /> ]]></programlisting>

		<programlisting language="java"><![CDATA[public class SomeClass {
  @Inject
  private PigTemplate template;

  public Set<String> getDbs() {
      return pigTemplate.execute(new PigCallback<Set<String>() {
         @Override
         public Set<String> doInPig(PigServer pig) throws ExecException, IOException {
            return pig.getAliasKeySet();
         }
      });
  }
}]]></programlisting>

		<para>The example above shows a basic container configuration wiring a <literal>PigTemplate</literal> into a user class which uses it to interact with the <literal>PigServer</literal> API. Notice that the 
		user does not have to handle the lifecycle of the <literal>PigServer</literal> instance or catch any exception - these are handled automatically by the template
		which converts them, like the rest of the Spring templates, into <literal>DataAccessException</literal>s. Thus the application only has to track only one exception hierarchy across all data technologies instead of 
		one per technology.</para>
	</section>
		
</chapter>
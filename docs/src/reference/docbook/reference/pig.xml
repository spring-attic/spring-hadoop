<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0"  xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="pig">

	<title>Pig support</title>
	
	<para>For <ulink url="http://pig.apache.org">Pig</ulink> users, SHDP provides easy creation and configuration of <interfacename>PigServer</interfacename> instances for registering and executing scripts either locally
	or remotely. In its simplest form, the declaration looks as follows:</para>
	
	<programlisting language="xml"><![CDATA[<hdp:pig />]]></programlisting>
	
	<para>This will create a <interfacename>PigServer</interfacename> instance, named <literal>hadoop-pig</literal>, configured with a default <interfacename>PigContext</interfacename>, 
	executing scripts in <literal>MapReduce</literal> mode. In typical scenarios however, one might want to connect to a remote Hadoop tracker and register some scripts automatically so let us take a look of how the
	configuration might look like:</para>
	
	<programlisting language="xml"><![CDATA[<pig exec-type="LOCAL" job-name="pig-script" configuration-ref="hadoop-configuration" xmlns="http://www.springframework.org/schema/hadoop">
   <properties>
     source=${pig.script.src}
   </properties>
   <script location="org/company/pig/script.pig">
     <arguments>electric=sea</arguments>
   </script>
   <script>
     A = LOAD 'src/test/resources/logs/apache_access.log' USING PigStorage() AS (name:chararray, age:int);
     B = FOREACH A GENERATE name;
     DUMP B;
   </script>
</pig> />]]></programlisting>
	
	<para>The example exposes quite a few options so let us review them one by one. First the top-level pig definition configures the pig instance: the execution type, the Hadoop configuration used and the job name. Notice that
	additional properties can be specified through the <literal>properties</literal> element. The definition contains also two scripts: <literal>script.pig</literal> (read from the classpath) to which one pair of arguments, 
	relevant to the script, is passed (notice the use of property placeholder) but also an inlined script, declared as part of the definition, without any arguments.</para>
	
	<para>As you can tell, the <literal>pig</literal> namespace offers several options pertaining to Pig configuration. 
	And, as with the other Hadoop-related integration, the underlying <interfacename>PigServer</interfacename> is bound to the enclosing application context life-cycle; that is, it will automatically start and stop along-side
	the application so one does not have to worry about its management.</para>
	
	<section id="pig:tasklet">
		<title>Using the Pig tasklet</title>

		<para>For Spring Batch environments, SHDP provides a dedicated tasklet to execute Pig queries, on demand, as part of a batch or workflow. The declaration is pretty straight forward:</para>
		
		<programlisting language="xml"><![CDATA[<hdp:pig-tasklet id="pig-script">
   <hdp:script location="org/company/pig/handsome.pig" />
</hdp:pig-tasklet>]]></programlisting>

		<para>The syntax of the scripts declaration is similar to that of the <literal>pig</literal> namespace.</para>	
	</section>
	
</chapter>
<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0"  xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="cascading">

	<title>Cascading integration</title>
	
	<para>SHDP provides basic support for <ulink url="http://www.cascading.org/">Cascading</ulink> library through the <literal>org.springframework.data.hadoop.cascading</literal> package - 
	one can create <literal>Flow</literal>s or <literal>Cascade</literal>s, either through XML or/and Java and execute them, either in a simplistic manner or as part of a Spring Batch job.
	In addition, dedicated <literal>Tap</literal>s for Spring environments are available.</para>
	
	<para>As Cascading is aimed at code configuration, typically one would configure the library programatically. Such code can easily be integrated into Spring in various ways - through 
	<literal><ulink url="http://static.springsource.org/spring/docs/3.2.x/spring-framework-reference/html/beans.html#beans-factory-class-static-factory-method">factory methods</ulink></literal> or 
	<literal>@Configuration</literal> and <literal>@Bean</literal> (see <ulink url="http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/beans.html#beans-java">this chapter
	</ulink> for more information). In short one uses Java code (or any JVM language for that matter) to create beans.</para>
	
	<para>For example, looking at the official Cascading sample (<ulink url="http://www.cascading.org/2012/07/09/cascading-for-the-impatient-part-2/">Cascading for the Impatient, Part2</ulink>)
	one can simply call the Cascading setup method from within the Spring container (<ulink url="http://github.com/Cascading/Impatient/blob/5c19c2d02fcf26b7c63ca6548a9239a9a764f302/part2/src/main/java/impatient/Main.java#L57">original</ulink> vs 
	<ulink url="http://github.com/SpringSource/spring-hadoop-samples/blob/6b2365ae80c84b6b037e18e1fe8749e839fcf33f/original-samples/cascading/src/main/java/impatient/Main.java#L67">updated</ulink>):</para>
	
	<programlisting language="java"><![CDATA[public class Impatient {
    public static FlowDef createFlowDef(String docPath, String wcPath) {
        // create source and sink taps
        Tap docTap = new Hfs(new TextDelimited(true, "\t"), docPath);
        Tap wcTap = new Hfs(new TextDelimited(true, "\t"), wcPath);

        // specify a regex operation to split the "document" text lines into a token stream
        Fields token = new Fields("token");
        Fields text = new Fields("text");
        RegexSplitGenerator splitter = new RegexSplitGenerator(token, "[ \\[\\]\\(\\),.]");
        // only returns "token"
        Pipe docPipe = new Each("token", text, splitter, Fields.RESULTS);

        // determine the word counts
        Pipe wcPipe = new Pipe("wc", docPipe);
        wcPipe = new GroupBy(wcPipe, token);
        wcPipe = new Every(wcPipe, Fields.ALL, new Count(), Fields.ALL);

        // connect the taps, pipes, etc., into a flow
        FlowDef flowDef = FlowDef.flowDef().setName("wc").addSource(docPipe, docTap).addTailSink(wcPipe, wcTap);
        return flowDef; }
}]]></programlisting>

    <para>The entire Cascading configuration (defining the <literal>Flow</literal>) is encapsulated within one method, which can be called by the container:</para>
    
    <programlisting language="xml"><![CDATA[<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:hdp="http://www.springframework.org/schema/hadoop"
    xmlns:c="http://www.springframework.org/schema/c"
    xmlns:p="http://www.springframework.org/schema/p"
    xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd
        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd">
    
    <!-- factory-method approach called with two parameters available as property placeholders -->
    <bean id="flowDef" class="impatient.Main" factory-method="createFlowDef" c:_0="${in}" c:_1="${out}"/>

    <hdp:cascading-flow id="wc" definition-ref="flowDef" write-dot="dot/wc.dot"/>
    <hdp:cascading-cascade id="cascade" flow-ref="wc"/>
    <hdp:cascading-runner unit-of-work-ref="cascade" run-at-startup="true"/>
</beans>]]></programlisting>
	
	<para>Note that no jar needs to be setup - the Cascading namespace (in particular <literal>cascading-flow</literal>, backed by <literal>FlowFactoryBean</literal>) tries to automatically setup the
	resulting job classpath. By default, it will automatically add the Cascading library and its dependency to Hadoop <literal>DistributedCache</literal> so that when the job runs inside the Hadoop
	cluster, the jars are properly found. When using custom jars (for example to add custom Cascading functions) or when running against a cluster that is already provisioned, one can customize this
	behaviour through the <literal>jar-setup</literal>, <literal>jar</literal> and <literal>jar-by-class</literal>. For Cascading users, these settings are the equivalent of the 
	<literal>AppProps.setApplicationJarClass()</literal>.</para>
	
	<para>Furthermore, one can break down the configuration method in multiple pieces which is useful for reusing the components between multiple flows/cascades. This goes hand in hand with Spring
	<literal>@Configuration</literal> feature - see the example below that configures a Cascade pipes and taps as individual beans 
	(see the original <ulink url="http://github.com/cwensel/cascading.samples/">example</ulink>):</para>
	
	<programlisting language="java"><![CDATA[@Configuration
public class CascadingAnalysisConfig {
    // fields that act as placeholders for externalized values
    @Value("${cascade.sec}") private String sec;
    @Value("${cascade.min}") private String min;
    
    @Bean public Pipe tsPipe() {
        DateParser dateParser = new DateParser(new Fields("ts"), "dd/MMM/yyyy:HH:mm:ss Z");
        return new Each("arrival rate", new Fields("time"), dateParser);
    }

    @Bean public Pipe tsCountPipe() {
        Pipe tsCountPipe = new Pipe("tsCount", tsPipe());
        tsCountPipe = new GroupBy(tsCountPipe, new Fields("ts"));
        return new Every(tsCountPipe, Fields.GROUP, new Count());
    }

    @Bean public Pipe tmCountPipe() {
        Pipe tmPipe = new Each(tsPipe(),
                new ExpressionFunction(new Fields("tm"), "ts - (ts % (60 * 1000))", long.class));
        Pipe tmCountPipe = new Pipe("tmCount", tmPipe);
        tmCountPipe = new GroupBy(tmCountPipe, new Fields("tm"));
        return new Every(tmCountPipe, Fields.GROUP, new Count());
    }

    @Bean public Map<String, Tap> sinks(){
        Tap tsSinkTap = new Hfs(new TextLine(), sec);
        Tap tmSinkTap = new Hfs(new TextLine(), min);
        return Cascades.tapsMap(Pipe.pipes(tsCountPipe(), tmCountPipe()), Tap.taps(tsSinkTap, tmSinkTap));
    }

    @Bean public String regex() {
        return "^([^ ]*) +[^ ]* +[^ ]* +\\[([^]]*)\\] +\\\"([^ ]*) ([^ ]*) [^ ]*\\\" ([^ ]*) ([^ ]*).*$";
    }
    
    @Bean public Fields fields() {
        return new Fields("ip", "time", "method", "event", "status", "size");
    }
}]]></programlisting>

	<para>The class above creates several objects (all part of the Cascading package) (named after the methods) which can be injected or wired just like any other bean 
	(notice how the wiring is done between the beans by point to their methods). One can mix and match (if needed) code and XML configurations inside the same application:</para>
	
	<programlisting language="xml"><![CDATA[<!-- code configuration class -->
<bean class="org.springframework.data.hadoop.cascading.CascadingAnalysisConfig"/>

<!-- Tap created through XML rather then code (using Spring's 3.1 c: namespace)-->
<bean id="tap" class="cascading.tap.hadoop.Hfs" c:fields-ref="fields" c:string-path-value="${cascade.input}"/>

<!-- standard bean declaration used to showcase the container flexibility -->
<!-- note the tap and sinks are imported from the CascadingAnalysisConfig bean -->
<bean id="analysisFlow" class="org.springframework.data.hadoop.cascading.HadoopFlowFactoryBean" p:configuration-ref="hadoopConfiguration" p:source-ref="tap" p:sinks-ref="sinks">
     <property name="tails"><list>
         <ref bean="tsCountPipe"/>
         <ref bean="tmCountPipe"/>
     </list></property>
    </bean>
  </list></property>
</bean>

<hdp:cascading-cascade flow="analysisFlow" />
<hdp:cascading-runner unit-of-work-ref="cascade" run-at-startup="true"/>]]></programlisting>

	<para>The XML above, whose main purpose is to illustrate possible ways of configuring, uses SHDP classes to create a <literal>Cascade</literal> with one nested <literal>Flow</literal> using the taps 
	and sinks configured by the code class. Additionally it also shows how the cascade is ran (through <literal>cascading-runner</literal>).
	The runner will trigger the execution during the application start-up (notice 
	the <literal>run-at-startup</literal> flag which is by default <literal>false</literal>). Do note that the runner will not run unless triggered manually or if <literal>run-at-startup</literal> is set to <literal>true</literal>.
	Additionally the runner (as in fact do all <link linkend="runners">runners</link> in SHDP) allows one or
	multiple <literal>pre</literal> and <literal>post</literal> actions to be specified to be executed before and after each run. Typically other runners (such as other jobs or scripts) can be specified but any JDK <literal>Callable</literal> can be 
	passed in. For more information on runners, see the <link linkend="runners">dedicated</link> chapter.
	</para>
	
	
	<para>Whether XML or Java config is better is up to the user and is usually based on the type of the configuration required. Java config suits Cascading better but note that the <literal>FactoryBean</literal>s
	above handle the lifecycle and some default configuration for both the <literal>Flow</literal> and <literal>Cascade</literal> objects. Either way, whatever option is used, SHDP fully supports it.</para>
	
	<section id="cascading:tasklet">
		<title>Using the Cascading tasklet</title>

		<para>For Spring Batch environments, SHDP provides a dedicated tasklet (similar to <literal>CascadeRunner</literal> above) for executing <literal>Cascade</literal> or <literal>Flow</literal> 
		instances, on demand, as part of a batch or workflow. The declaration is pretty straightforward:</para>
		
		<programlisting language="xml"><![CDATA[<hdp:tasklet p:unit-of-work-ref="cascade" />]]></programlisting>
	</section>
	
	<section id="cascading:scalding">
		<title>Using Scalding</title>
		
		<para>There are quite a number of DSLs built on top of Cascading, most noteably <ulink url="https://github.com/nathanmarz/cascalog">Cascalog</ulink> (written in Clojure) and 
		<ulink url="https://github.com/twitter/scalding">Scalding</ulink> (written in Scala). This documentation will cover Scalding however the same concepts can be applied across the board to all
		DSLs.</para>
		
		<para>As with the rest of the DSLs, Scalding offers a simplified, fluent syntax for creating units of code that build on top of Cascading. This in turn translates to Map Reduce jobs that get executed on Hadoop.
		Once compiled, the DSL gets translated into actual JVM classes that get executed by Scalding through its own <literal>Tool</literal> instance (namely <classname>com.twitter.scalding.Tool</classname>).
		One has the option of either deploy the Scalding jobs directly (by invoking the aforementioned <literal>Tool</literal>) or use Scalding's <literal>scald.rb</literal> script which does the same thing based
		on the various attributes passed to it. Both approaches can be used in SHDP, the former through the <link linkend="hadoop:tool-runner">Tool</link> support (described below) and the latter by invoking the 
		<literal>scald.rb</literal> script directly through the <link linkend="scripting">scripting</link> feature.</para>
		
		<para>For example, to run the tutorial examples (say Tutorial1), one can issue the following command:</para>
		<programlisting>scripts/scald.rb --local tutorial/Tutorial1.scala</programlisting>
		
		<para>which compiles Tutorial1, creates a bundled jar and runs it on a local Hadoop instance. When using the <literal>Tool</literal> support, the compilation and the library provisioning are external tasks 
		(just as in the case of typical Hadoop jobs). The SHDP configuration to run the tutorial looks as follows:</para>
		
		<programlisting language="xml"><![CDATA[<!-- the tool automatically is injected with 'hadoopConfiguration' -->
<hdp:tool-runner id="scalding" tool-class="com.twitter.scalding.Tool">
   <hdp:arg value="tutorial/Tutorial1"/>
   <hdp:arg value="--local"/>
</hdp:tool-runner>]]></programlisting>
	</section>
	
	<section id="cascading:tap:local">
		<title>Spring-specific local <literal>Tap</literal>s</title>
		
		<sidebar>
			<title>Why only local <literal>Tap</literal>?</title>
			<para>Because Hadoop is designed as a distributed file-system (HDFS) and splitable resources. Non-HDFS resources tend to not be cluster friendly: for example don't offer any notion of node locality, true chucking
			or even scalability (as there are no copies, partial or not made). These being said, the team is pursuing certain approaches to see whether they are viable or not. Feedback is of course welcome.</para>
		</sidebar>
		
		<para>Besides dedicated configuration support, SHDP also provides <emphasis>read-only</emphasis> <literal>Tap</literal> implementations useful inside Spring environments. Currently they are meant for 
		<emphasis>local</emphasis> use only such as	testing or single-node Hadoop setups.</para> 
		<para>The <literal>Tap</literal>s in <literal>org.springframework.data.hadoop.cascading.tap.local</literal> tap (pun intended) into the rich resource support from Spring Framework and Spring Integration
		allowing data to flow easily in and out of a Cascading flow. </para>
		<para> </para>
		<para>Below is a list of the type of <literal>Tap</literal>s available and their backing support.</para>
		
		<table id="cascading:tap:local:table" pgwide="1" align="center">
 			<title>Local <literal>Tap</literal>s</title>
 			
 			<tgroup cols="4">
 			<colspec colname="c1" colwidth="1*"/>
    		<colspec colname="c2" colwidth="1*"/>
    		<colspec colname="c3" colwidth="1*"/>
    		<colspec colname="c4" colwidth="2*"/>
    		
    		<thead>
          	   <row>
          	     <entry>Tap Name</entry>
          	     <entry>Tap Type</entry>
          	     <entry>Backing Resource</entry>
          	     <entry>Resource Description</entry>
          	   </row>
       	    </thead>
       	    <tbody>
          	   <row>
          	      <entry><literal>ResourceTap</literal></entry>
          	      <entry>Source</entry>
          	      <entry>Spring <literal><ulink url="http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/core/io/Resource.html">Resource</ulink></literal></entry>
          	      <entry>classpath, file-system, URL-based or even in-memory <ulink url="http://static.springsource.org/spring/docs/3.1.x/spring-framework-reference/html/resources.html#resources-implementations">content</ulink></entry>
          	    </row>
          	   <row>
          	      <entry><literal>MessageSourceTap</literal></entry>
          	      <entry>Source</entry>
          	      <entry>Spring Integration <ulink url="http://static.springsource.org/spring-integration/api/org/springframework/integration/core/MessageSource.html">MessageSource</ulink></entry>
          	      <entry>Inbound adapter for anything from arbitrary streams, FTP or JDBC to RSS/Atom and Twitter</entry>
          	    </row>
          	   <row>
          	      <entry><literal>MessageHandlerTap</literal></entry>
          	      <entry>Sink</entry>
          	      <entry>Spring Integration <ulink url="http://static.springsource.org/spring-integration/api/index.html?org/springframework/integration/core/MessageSource.html">MessageHandler</ulink></entry>
          	      <entry>The opposite of <literal>MessageSourceTap</literal>: Outbound adapter for Files, JMS, TCP, etc...</entry>
          	    </row>
          	</tbody>
          	</tgroup>   
 		</table>
		
		<para>
		Note the <literal>Tap</literal>s do not require any special configuration and are fully compatible with the existing Cascading local <literal>Scheme</literal>s. To wit:
		</para>
		
		<programlisting language="xml"><![CDATA[<bean id="cp-txt-files" class="org.springframework.data.hadoop.cascading.tap.local.ResourceTap">
	<constructor-arg><bean class="cascading.scheme.local.TextLine"/></constructor-arg>
	<constructor-arg><value>classpath:/data/*.txt</value></constructor-arg>
</bean>]]></programlisting>

		<para>The <literal>Tap</literal> above reads all the text files in the classpath, under <literal>data</literal> folder, through Cascading <literal>TextLine</literal>. Simply wire that to a Cascading flow 
		(as described in the previous section) and you are good to go.</para>
	</section>
	
</chapter>
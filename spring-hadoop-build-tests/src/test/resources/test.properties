#
# Hadoop/Hive/Pig settings used for settings
#
# Note: the system properties are checked first - that is the command-line takes precedence (useful for CI) 

# Amazon EMR
# hive.port=10003
# hd.fs=s3n://work-emr/tmp
# hd.jt=localhost:20001
# hd.jt=10.80.205.79:9001

# Apache Whirr - EC2
# hd.fs=hdfs://xxx.amazonaws.com:8020
# hd.jt=xxx.amazonaws.com:8021

# Default - Vanilla Installs
#hd.fs=hdfs://${hadoop.host:localhost}:${hadoop.port:9000}

#
# Hadoop settings
#

## M&R
hadoop.fs=${hd.fs|hdfs://localhost:8020}
hadoop.rm=${hd.rm|localhost:8032}
hadoop.jh=${hd.jh|localhost:10020}

## Hive
hive.host=${hd.hive.host|localhost}
hive.port=${hd.hive.port|10000}
hive.url=jdbc:hive2://${hive.host}:${hive.port}

## HBase
hbase.host=${hd.hbase.host|localhost}
hbase.port=${hd.hbase.port|2181}

## Pig Execution
## externalized since CDH3 VM Pig install has issues (SL4J CNFE) 
pig.execution=${hd.pig.exec|LOCAL}

#
# Other settings
#

#path.cat=bin${file.separator}stream-bin${file.separator}cat
#path.wc=bin${file.separator}stream-bin${file.separator}wc
path.cat=cat
path.wc=wc

input.directory=logs
log.input=/logs/input/
log.output=/logs/output/

distcp.src=${hadoop.fs}/distcp/source.txt
distcp.dst=${hadoop.fs}/distcp/dst

cascade.sec=/test/cascading/loganalysis/sec
cascade.min=/test/cascading/loganalysis/min
<beans xmlns="https://www.springframework.org/schema/beans"
	xmlns:xsi="https://www.w3.org/2001/XMLSchema-instance"
    xmlns:batch="https://www.springframework.org/schema/batch"
	xmlns:hdp="https://www.springframework.org/schema/hadoop"
	xmlns:c="https://www.springframework.org/schema/c"
	xmlns:p="https://www.springframework.org/schema/p"
	xsi:schemaLocation="https://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd
      	https://www.springframework.org/schema/batch	https://www.springframework.org/schema/batch/spring-batch.xsd
      	https://www.springframework.org/schema/hadoop https://www.springframework.org/schema/hadoop/spring-hadoop.xsd">

	<import resource="../batch-common.xml"/>
	<hdp:configuration register-url-handler="false">
		fs.defaultFS=file:///
		mapreduce.framework.name=local
	</hdp:configuration>

	<hdp:script language="javascript" run-at-startup="true">
		log="src/test/resources/logs/apache_access.log"
		if (!fsh.test(log)) {
			fs.copyFromLocalFile(log, log)
			print("Copied Pig log files to HDFS")
 		}
	</hdp:script>	
	
	
	<job id="mainJob" xmlns="https://www.springframework.org/schema/batch">
		<step id="bean" next="do-pig">
			<tasklet ref="tasklet"/>
		</step>
		<step id="do-pig">
			<tasklet ref="pig-script"/>
		</step>
	</job>

	<bean id="tasklet" class="org.springframework.data.hadoop.batch.pig.PigTasklet" p:pig-factory-ref="pigFactory">
		<property name="scripts">
			<list>
				<bean class="org.springframework.data.hadoop.pig.PigScript">
					<constructor-arg name="resource" value="org/springframework/data/hadoop/pig/script.pig"/>
				</bean>
			</list>
		</property>
	</bean>

	<hdp:pig-factory configuration-ref="hadoopConfiguration" exec-type="LOCAL" job-name="pig-script"/>
	
	<hdp:pig-tasklet id="pig-script" scope="prototype">
		<hdp:script location="org/springframework/data/hadoop/pig/script.pig" />
	</hdp:pig-tasklet>
	
</beans>

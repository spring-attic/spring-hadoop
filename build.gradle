buildscript {
    repositories {
        maven { url 'http://repo.springsource.org/plugins-release' }
    }
    dependencies {
        classpath 'org.springframework.build.gradle:docbook-reference-plugin:0.1.6'
    }
}

description = 'Spring for Apache Hadoop'
group = 'org.springframework.data'

repositories {
  maven { url "http://repo.springsource.org/libs-snapshot" }
}

apply plugin: "java"
apply plugin: 'eclipse'
apply plugin: 'idea'
apply from: "$rootDir/maven.gradle"
apply plugin: 'docbook-reference'


// 
//  Select the Hadoop distribution used for building the binaries
// 
def List hadoop = []
def hadoopDistro = project.hasProperty("distro") ? project.getProperty("distro") : "hadoop10"
def hadoopVersion = hadoop10Version

// default is Hadoop 1.0.x
switch (hadoopDistro) {

  // Cloudera CDH3
  case "cdh3":
    hadoopVersion = cdh3Version
    println "Using Cloudera CDH3 [$hadoopVersion]"
    
    dependencies {
        compile ("org.apache.hadoop:hadoop-streaming:$hadoopVersion", optional) 
        compile ("org.apache.hadoop:hadoop-tools:$hadoopVersion", optional)
    }

  break;    

  // Cloudera CDH4
  case "cdh4":
    hadoopVersion = cdh4MR1Version
    println "Using Cloudera CDH4 [$hadoopVersion]"

    dependencies {
        compile ("org.apache.hadoop:hadoop-streaming:$hadoopVersion", optional) 
        compile ("org.apache.hadoop:hadoop-tools:$hadoopVersion", optional)
        compile ("org.apache.hadoop:hadoop-common:$cdh4Version", optional)
        compile ("org.apache.hadoop:hadoop-hdfs:$cdh4Version", optional)
    }

  break;    

  // Hadoop 1.1.x
  case "hadoop11":
    hadoopVersion = hadoop11Version
    
    println "Using Apache Hadoop 1.1.x [$hadoopVersion]"
    
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"]
  break;

  default:
    println "Using Apache Hadoop 1.0.x [$hadoopVersion]"
    hadoopVersion = hadoop10Version
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"]
}

// make Hadoop dependencies optional
//hadoop = hadoop.collect { it.concat(", optional") }


// Common dependencies
dependencies {
    compile hadoop
    
    // Logging
    compile "org.slf4j:slf4j-api:$slf4jVersion"
    compile ("org.slf4j:jcl-over-slf4j:$slf4jVersion", optional)
    testRuntime "log4j:log4j:$log4jVersion"
    testRuntime "org.slf4j:slf4j-log4j12:$slf4jVersion"

    // Spring Framework
    compile("org.springframework:spring-core:$springVersion") {
        exclude module: "commons-logging"
    }
    compile "org.springframework:spring-context-support:$springVersion"
    compile("org.springframework:spring-tx:$springVersion", optional)
    compile("org.springframework:spring-aop:$springVersion", optional)
    compile("org.springframework:spring-jdbc:$springVersion", optional)
    compile("org.springframework.batch:spring-batch-core:$springBatchVersion", optional)
    compile("org.springframework.integration:spring-integration-stream:$springIntVersion", optional)
    compile("org.springframework.integration:spring-integration-file:$springIntVersion", optional)


    // cascading
    compile("cascading:cascading-hadoop:$cascadingVersion") { dep ->
        optional dep
        exclude module: "hadoop-core"
    }
    
    // Missing dependency in Hadoop 1.0.3
    testRuntime "commons-io:commons-io:$commonsioVersion"
    //testRuntime "org.codehaus.jackson:jackson-core-asl:$jacksonVersion"
    testRuntime "org.codehaus.jackson:jackson-mapper-asl:$jacksonVersion"
    testRuntime "cglib:cglib:$cglibVersion"

    // Hive
    compile("org.apache.hive:hive-metastore:$hiveVersion", optional) 
    compile("org.apache.hive:hive-service:$hiveVersion", optional)

    testRuntime "org.apache.hive:hive-common:$hiveVersion"
    testRuntime "org.apache.hive:hive-jdbc:$hiveVersion"
    testRuntime "org.apache.hive:hive-shims:$hiveVersion"
    testRuntime "org.apache.hive:hive-serde:$hiveVersion"
    testRuntime "org.apache.thrift:libthrift:$thriftVersion"
    testRuntime "org.apache.thrift:libfb303:$thriftVersion"

    // Pig
    compile("org.apache.pig:pig:$pigVersion", optional)
    
    // HBase
    compile("org.apache.hbase:hbase:$hbaseVersion") { dep ->
        optional dep
        exclude module: "thrift"
    }

    // Libs dependencies (specified to cope with incompatibilities between them)
    // testRuntime "org.antlr:antlr:$antlrVersion"
    // testRuntime "org.antlr:antlr-runtime:$antlrVersion"

    
    // Testing
    testCompile "junit:junit:$junitVersion"
    testCompile "org.mockito:mockito-core:$mockitoVersion"
    testCompile "org.springframework:spring-test:$springVersion"
    testCompile("javax.annotation:jsr250-api:1.0", optional)
    testCompile "org.apache.hadoop:hadoop-examples:$hadoopVersion"
    
    testRuntime "org.springframework.integration:spring-integration-event:$springIntVersion"
    
    testRuntime "org.codehaus.groovy:groovy:$groovyVersion"
    testRuntime "org.jruby:jruby:$jrubyVersion"
    testRuntime "org.python:jython-standalone:$jythonVersion"
    testRuntime "org.apache.hive:hive-builtins:$hiveVersion"

    // specify a version of antlr that works with both hive and pig
    testRuntime "org.antlr:antlr-runtime:$antlrVersion"
    testCompile "cascading:cascading-local:$cascadingVersion"
    
}

// exclude poms from the classpath (pulled in by Cloudera)
eclipse.classpath.file {
    whenMerged { classpath ->
        classpath.entries.removeAll { entry -> entry.toString().contains(".pom") }
    }
}

sourceCompatibility = 1.6
targetCompatibility = 1.6 

ext.skipPig = true
ext.skipHive = true
ext.skipHBase = true
ext.skipWebHdfs = true

task enablePigTests {
    description = "Enable Pig tests"
    group = "Verification"
    
    doLast() {
        project.ext.skipPig = false
   }
}

task enableHiveTests {
    description = "Enable Hive tests"
    group = "Verification"
    doLast() {
        project.ext.skipHive = false
   }
}

task enableHBaseTests {
    description = "Enable HBase tests"
    group = "Verification"
    doLast() {
        project.ext.skipHBase = false
    }
}

task enableWebHdfsTests {
    description = "Enable WebHdfs tests"
    group = "Verification"
    doLast() {
        project.ext.skipWebHdfs = false
    }
}

task enableAllTests() {
    description = "Enable all (incl. Pig, Hive, HBase, WebHdfs) tests"
    group = "Verification"
    doFirst() {
      println "Enable all tests"
      project.ext.skipPig = false
      project.ext.skipHBase = false
      project.ext.skipHive = false
      project.ext.skipWebHdfs = false
    }
}

test {
    //forkEvery = 1
    systemProperties['input.path'] = 'build/classes/test/input'
    systemProperties['output.path'] = 'build/classes/test/output'
    includes = ["**/*.class"]


    doFirst() {
        ext.msg = ""
        
        if (skipPig) {
            ext.msg += "Pig "
            excludes.add("**/pig/**")
        }
        if (skipHBase) {
            ext.msg += "HBase "
            excludes.add("**/hbase/**")
        }
        
        if (skipHive) {
            ext.msg += "Hive "
            excludes.add("**/hive/**")
        }

        if (skipWebHdfs) {
            ext.msg += "WebHdfs"
            excludes.add("**/WebHdfs*")
        }
        
        if (!msg.isEmpty())
            println "Skipping [$msg] Tests";
        
        // check prefix for hd.fs
        // first copy the properties since we can't change them
        ext.projProps = project.properties
        
        if (projProps.containsKey("hd.fs")) {
            String hdfs = projProps["hd.fs"].toString()
            if (!hdfs.contains("://")) {
                projProps.put("hd.fs", "hdfs://" + hdfs)
            }
        }
            
        // due to GRADLE-2475, set the system properties manually
        projProps.each { k,v ->
             if (k.toString().startsWith("hd.")) {
                systemProperties[k] = projProps[k]
             }
        }
    }
}

javadoc {
  ext.srcDir = file("${projectDir}/docs/src/api")
  
  configure(options) {
      stylesheetFile = file("${srcDir}/spring-javadoc.css")
      overview = "${srcDir}/overview.html"
      docFilesSubDirs = true
      outputLevel = org.gradle.external.javadoc.JavadocOutputLevel.QUIET
      breakIterator = true
      author = true
      showFromProtected()
      
//      groups = [
//        'Spring Data Hadoop' : ['org.springframework.data.hadoop*'],
//      ]
  
     links = [
        "http://static.springframework.org/spring/docs/3.0.x/javadoc-api",
        "http://download.oracle.com/javase/6/docs/api",
        "http://logging.apache.org/log4j/1.2/apidocs/",
        "http://hadoop.apache.org/common/docs/current/api/",
        "http://hbase.apache.org/apidocs/",
        "http://pig.apache.org/docs/r0.9.2/api/",
        "http://hive.apache.org/docs/r0.8.1/api/",
        "http://static.springsource.org/spring-batch/apidocs/",
        "http://static.springsource.org/spring-integration/api/",
        "https://builds.apache.org/job/Thrift/javadoc/",
        "http://jakarta.apache.org/commons/logging/apidocs/",
        "http://docs.cascading.org/cascading/2.0/javadoc/"
     ]
     
     exclude "org/springframework/data/hadoop/config/**"
  }
    
  title = "${rootProject.description} ${version} API"
}

jar {
    manifest.attributes['Implementation-Title'] = 'spring-data-hadoop'
    manifest.attributes['Implementation-Version'] = project.version
    manifest.attributes['Build'] = "" + System.env['SHDP.BUILD']
    manifest.attributes['Repository-Revision'] = "" + System.env['SHDP.REV']

    from("$rootDir/docs/src/info") {
        include "license.txt"
        include "notice.txt"
        into "META-INF"
        expand(copyright: new Date().format('yyyy'), version: project.version)
    }
}

task sourcesJar(type: Jar, dependsOn:classes) {
    classifier = 'sources'
    from sourceSets.main.allJava
}

task javadocJar(type: Jar) {
    classifier = 'javadoc'
    from javadoc
}

reference {
    sourceDir = file('docs/src/reference/docbook')
    //pdfFileName = 'spring-data-hadoop-reference.pdf'
}


task docsZip(type: Zip) {
    group = 'Distribution'
    classifier = 'docs'
    description = "Builds -${classifier} archive containing api and reference for deployment"

    from('docs/src/info') {
        include 'changelog.txt'
    }

    from (javadoc) {
        into 'api'
    }

    from (reference) {
        into 'reference'
    }
}

task schemaZip(type: Zip) {
    group = 'Distribution'
    classifier = 'schema'
    description = "Builds -${classifier} archive containing all XSDs for deployment"

    def Properties schemas = new Properties();
    
    sourceSets.main.resources.find {
        it.path.endsWith('META-INF' + File.separator + 'spring.schemas')
    }?.withInputStream { schemas.load(it) }

    for (def key : schemas.keySet()) {
        def shortName = key.replaceAll(/http.*schema.(.*).spring-.*/, '$1')
        def alias = key.replaceAll(/http.*schema.(.*).(spring-.*)/, '$2')
        assert shortName != key
        File xsdFile = sourceSets.main.resources.find {
            it.path.replace('\\', '/').endsWith(schemas.get(key))
        }
        assert xsdFile != null
        
        into (shortName) {
           from xsdFile.path
           rename { String fileName -> alias }
        }
    }    
}

task distZip(type: Zip, dependsOn: [jar, docsZip, schemaZip, sourcesJar, javadocJar]) {
    group = 'Distribution'
    classifier = 'dist'
    description = "Builds -${classifier} archive, containing all jars and docs, " +
                  "suitable for community download page."

    ext.zipRootDir = "${project.name}-${project.version}"

    into (zipRootDir) {
        from('docs/src/info') {
            include 'readme.txt'
            include 'license.txt'
            include 'notice.txt'
            expand(copyright: new Date().format('yyyy'), version: project.version)
        }

        from('samples/') {
                into 'samples'
                exclude '**/build/**'
                exclude '**/bin/**'
                exclude '**/.settings/**'
                exclude '**/.gradle/**'
                exclude '**/.*'
        }
        
        from(zipTree(docsZip.archivePath)) {
            into "docs"
        }

        from(zipTree(schemaZip.archivePath)) {
            into "schema"
        }
        into ("dist") {
            from rootProject.collect { project -> project.libsDir }
        }
    }
}

artifacts {
    archives sourcesJar
    archives javadocJar

    archives docsZip
    archives schemaZip
    archives distZip
}

task wrapper(type: Wrapper) {
    description = 'Generates gradlew[.bat] scripts'
    gradleVersion = '1.3'
}

assemble.dependsOn = ['jar', 'sourcesJar']
defaultTasks 'build'